{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "Data = pd.DataFrame()\n",
        "\n",
        "for re in result_101:\n",
        "    office_name = re['officeName']\n",
        "    title = re['title']\n",
        "    summary = re['summary']\n",
        "    office_id = re['officeId'] # 신문사에 대한 코드\n",
        "    article_id = re['articleId'] # 기사 제목에 대한 코드\n",
        "    \n",
        "    base_url = 'https://n.news.naver.com/mnews/article/'\n",
        "    article_url = base_url + office_id + '/' + article_id\n",
        "    \n",
        "    new_df = pd.DataFrame({'신문사': office_name, '제목': title, '기사 요약': summary,\n",
        "                          'URL': article_url}, index=[0])\n",
        "    \n",
        "    Data = pd.concat([Data, new_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "Jie_qv6lwGV1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "Category_code = ['103', '101', '102',  '105', '104', '100'] # 경제, 사회, IT/과학, 세계\n",
        "Category = ['생활/문화', '경제', '사회', 'IT/과학', '세계', '정치']\n",
        "\n",
        "Data = pd.DataFrame()\n",
        "\n",
        "for cate_code, category in zip(Category_code, Category):\n",
        "    for page in range(1, 11):\n",
        "        url = f'https://news.naver.com/main/mainNews.naver?sid1={cate_code}&date=%2000:00:00&page={page}'\n",
        "        headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\"}\n",
        "        response = requests.get(url, headers = headers) # 페이지 불러오기\n",
        "        ticket = response.json()\n",
        "\n",
        "        airsResult = ticket['airsResult'] # 1차 진입\n",
        "        dic_result = json.loads(airsResult) # 딕셔너리 전환\n",
        "\n",
        "        result = dic_result['result']\n",
        "        result_with_code = result[cate_code]\n",
        "\n",
        "        base_url = 'https://n.news.naver.com/mnews/article/'\n",
        "\n",
        "        for res in result_with_code:\n",
        "            title = res['title']\n",
        "            summary = res['summary']\n",
        "            office_id = res['officeId']\n",
        "            article_id = res['articleId']\n",
        "            office_name = res['officeName']\n",
        "            article_url = base_url + office_id + '/' + article_id\n",
        "\n",
        "            new_df = pd.DataFrame({'카테고리': category, '제목': title, \n",
        "                                  '언론사': office_name, 'URL': article_url}, index=[0])\n",
        "            \n",
        "            Data = pd.concat([Data, new_df], ignore_index = True)\n",
        "            \n",
        "        print(f'{page} of {category} Page was Done')\n",
        "        time.sleep(random.uniform(1, 2)) # 한 페이지가 끝난 후 1초에서 2초 사이 휴식     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTceuB87wZGy",
        "outputId": "72a72aed-bbdb-404e-962a-f738533fad18"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 of 생활/문화 Page was Done\n",
            "2 of 생활/문화 Page was Done\n",
            "3 of 생활/문화 Page was Done\n",
            "4 of 생활/문화 Page was Done\n",
            "5 of 생활/문화 Page was Done\n",
            "6 of 생활/문화 Page was Done\n",
            "7 of 생활/문화 Page was Done\n",
            "8 of 생활/문화 Page was Done\n",
            "9 of 생활/문화 Page was Done\n",
            "10 of 생활/문화 Page was Done\n",
            "1 of 경제 Page was Done\n",
            "2 of 경제 Page was Done\n",
            "3 of 경제 Page was Done\n",
            "4 of 경제 Page was Done\n",
            "5 of 경제 Page was Done\n",
            "6 of 경제 Page was Done\n",
            "7 of 경제 Page was Done\n",
            "8 of 경제 Page was Done\n",
            "9 of 경제 Page was Done\n",
            "10 of 경제 Page was Done\n",
            "1 of 사회 Page was Done\n",
            "2 of 사회 Page was Done\n",
            "3 of 사회 Page was Done\n",
            "4 of 사회 Page was Done\n",
            "5 of 사회 Page was Done\n",
            "6 of 사회 Page was Done\n",
            "7 of 사회 Page was Done\n",
            "8 of 사회 Page was Done\n",
            "9 of 사회 Page was Done\n",
            "10 of 사회 Page was Done\n",
            "1 of IT/과학 Page was Done\n",
            "2 of IT/과학 Page was Done\n",
            "3 of IT/과학 Page was Done\n",
            "4 of IT/과학 Page was Done\n",
            "5 of IT/과학 Page was Done\n",
            "6 of IT/과학 Page was Done\n",
            "7 of IT/과학 Page was Done\n",
            "8 of IT/과학 Page was Done\n",
            "9 of IT/과학 Page was Done\n",
            "10 of IT/과학 Page was Done\n",
            "1 of 세계 Page was Done\n",
            "2 of 세계 Page was Done\n",
            "3 of 세계 Page was Done\n",
            "4 of 세계 Page was Done\n",
            "5 of 세계 Page was Done\n",
            "6 of 세계 Page was Done\n",
            "7 of 세계 Page was Done\n",
            "8 of 세계 Page was Done\n",
            "9 of 세계 Page was Done\n",
            "10 of 세계 Page was Done\n",
            "1 of 정치 Page was Done\n",
            "2 of 정치 Page was Done\n",
            "3 of 정치 Page was Done\n",
            "4 of 정치 Page was Done\n",
            "5 of 정치 Page was Done\n",
            "6 of 정치 Page was Done\n",
            "7 of 정치 Page was Done\n",
            "8 of 정치 Page was Done\n",
            "9 of 정치 Page was Done\n",
            "10 of 정치 Page was Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "\n",
        "Contents_data= pd.DataFrame()\n",
        "\n",
        "for category, journal, url in zip(Data['카테고리'], Data['언론사'], Data['URL']):\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\"}\n",
        "    \n",
        "    response = requests.get(url, headers = headers) # 페이지 불러오기\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    \n",
        "    title = soup.find('h2', attrs={'class' : 'media_end_head_headline'}).get_text() #  제목\n",
        "    contents = soup.find('div', attrs={'id' : 'dic_area'}).get_text() # 기사 내용\n",
        "    \n",
        "    new_contents_data = pd.DataFrame({'Category': category, 'Title': title,  'Contents': contents,\n",
        "                                     }, index=[0])\n",
        "    \n",
        "    Contents_data = pd.concat([Contents_data, new_contents_data])\n",
        "    time.sleep(random.uniform(1, 2)) # 한 페이지가 끝난 후 1초에서 2초 사이 휴식\n",
        "    \n",
        "Contents_data.head()"
      ],
      "metadata": {
        "id": "8AkPonI7xLvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Contents_data.to_csv(\"news.csv\", mode='w')"
      ],
      "metadata": {
        "id": "7xE3i55m4Rxd"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}